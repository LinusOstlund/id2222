{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report - Finding similar items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"abcdab\"\n",
    "s2 = \"Får får lammdab\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-shingles\n",
    "\n",
    "> A class&nbsp;<em>Shingling</em>&nbsp;that constructs&nbsp;<em>k</em>–shingles of a given length&nbsp;<em>k</em> (e.g., 10) from a given document, computes a hash value for each unique shingle and represents the document in the form of an ordered set of its hashed&nbsp;<em>k</em>-shingles.\n",
    "\n",
    "* Between two documents\n",
    "* Hash shingles\n",
    "    * vad är en bra hash funktion? Finns i boken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shingle(s, k=5):\n",
    "    \"\"\"\n",
    "    Split a string into k equal sizes\n",
    "    TODO: remove upper case and what not? Now I remove it :) \n",
    "    \"\"\"\n",
    "    return set([s[i:(i+k)].lower() for i in range(0, len(s)-k+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pyhon's native hash function with congruens to limit the possible outcomes.\n",
    "This function returns a set of all unique functions. I think it is correct, according to [Stanford's slides](http://www.mmds.org/mmds/v2.1/ch03-lsh.pdf), page 22:\n",
    "\n",
    "> Each **unique shingle** is a dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashed_shingles(document, k=5, hash_boundary = 2**32):\n",
    "    shingles = shingle(document, k)\n",
    "    hashed_shingles = [hash(shingle) % hash_boundary for shingle in shingles]\n",
    "    return set(hashed_shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bcd', 'cda', 'dab', 'abc'}\n",
      "{603619785, 286046921, 1196472809, 3673230799}\n",
      "{'mmd', 'r l', 'r f', 'får', ' la', 'mda', 'dab', 'år ', 'amm', ' få', 'lam'}\n",
      "{1177382594, 4098313827, 3878788484, 2320198341, 1986240005, 4016560105, 1196472809, 1306261067, 1262776890, 4207179418, 2117958527}\n"
     ]
    }
   ],
   "source": [
    "# SANDBOX - setting test variables and testing functions\n",
    "k = 3\n",
    "\n",
    "print(shingle(s1, k=k))\n",
    "h1 = get_hashed_shingles(s1, k=k)\n",
    "print(h1)\n",
    "\n",
    "print(shingle(s2, k=k))\n",
    "h2 = get_hashed_shingles(s2, k=k)\n",
    "print(h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CompareSets\n",
    "\n",
    "> A class&nbsp;<em>CompareSets </em>computes the Jaccard similarity of two sets of integers – two sets of hashed shingles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the lecture:\n",
    "\n",
    "> Column similarirty is the Jaccard similarity of the corresponding sets (rows with value 1) and can be computed using bitwise AND (for intersection) and bitwise OR (for union)\n",
    "\n",
    "Example:\n",
    "\n",
    "If $C_1$ and $C_2$ are a transposed columns, we can follow this approach using bitwise OR and AND to find their Jaccardi Distance:\n",
    "\n",
    "$$ \n",
    "C_1 = 011010, \\quad C_2 = 101011 \\\\ \n",
    "C_1 \\cup C_2 = C_1 \\lor C_2 = 5 \\\\\n",
    "C_1 \\cap C_2 = C_1  \\land C_2 = 2 \\\\ \\\\\n",
    "\\text{Jaccardi distance} = \\frac{|C_1 \\cap C_2|}{|C_1 \\cup C_2|} = \\frac{2}{5}\n",
    "$$\n",
    "\n",
    "Python has native support for comparing sets in such a manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1196472809}\n",
      "{1177382594, 4098313827, 3878788484, 2320198341, 1986240005, 603619785, 286046921, 1196472809, 4016560105, 1306261067, 3673230799, 4207179418, 1262776890, 2117958527}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07142857142857142"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sandbox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "intersection = h1 & h2\n",
    "union = h1 | h2\n",
    "\n",
    "print(intersection)\n",
    "print(union)\n",
    "len(intersection) / len(union)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(A, B):\n",
    "    \"\"\"\n",
    "    Jaccardi similarity between two sets of hashed shingles.\n",
    "    \"\"\"\n",
    "    return len(A & B) / len(A | B)\n",
    "\n",
    "def distance(A, B):\n",
    "    \"\"\"\n",
    "    Jaccardi distance.\n",
    "    \"\"\"\n",
    "    return 1-similarity(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3793103448275862"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SANDBOX - setting test data\n",
    "d3 = \"Jag heter Linus Östlund och är en kille\"\n",
    "d4 = \"Heter jag Linus Östlund och varför är jag en kille?\"\n",
    "d5 = \"En kille heter Linus Östlund och är jag en kille?\"\n",
    "\n",
    "h3 = get_hashed_shingles(d3)\n",
    "h4 = get_hashed_shingles(d4)\n",
    "h5 = get_hashed_shingles(d5)\n",
    "\n",
    "similarity(h3, h4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinHashing\n",
    "\n",
    "> A class&nbsp;<em>MinHashing</em>&nbsp;that builds a minHash signature (in the form of a vector or a set) of a given length&nbsp;<em>n</em>&nbsp;from a given set of integers (a set of hashed shingles).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_characteristic_matrix(documents_of_hashed_shingles):\n",
    "    \"\"\"\n",
    "    Produce the characteristic matris.\n",
    "    INPUT: documents_of_hashed_shingles -- a list of lists, where each element are a list of a document's hashed shingles.\n",
    "    NOTE Total amount of shingles must be sorted!\n",
    "    Returns a (shingles x documents) matrix with 0 and 1's\n",
    "    TODO is it really necessary to compute this or should it be avoided? Might be very large and poor time complexity.\n",
    "    TODO the input is not documents. Would it be better to just input the documents?\n",
    "    \"\"\"\n",
    "    # Get the union of all shingles, which are the rows in the characteristic matrix\n",
    "    union_of_shingles = get_union_of_shingles(documents_of_hashed_shingles)\n",
    "    # Get the number of documents, which are the columns in the characteristic matrix\n",
    "    number_of_documents = ['D'+str(i) for i in range(len(documents_of_hashed_shingles))]\n",
    "    # Initiate an empty characteristic matrix and then populate it\n",
    "    cm = np.zeros((len(union_of_shingles), len(documents_of_hashed_shingles)))\n",
    "    for i, shingle in enumerate(union_of_shingles):\n",
    "        for j, hashed_shingles in enumerate(documents_of_hashed_shingles):\n",
    "            if shingle in hashed_shingles:\n",
    "                cm[i][j] = 1\n",
    "    # return a pandas dataframe for easier viewing\n",
    "    return pd.DataFrame(cm, columns=number_of_documents, index=union_of_shingles, dtype=int) # kan sätta som 'bool' med dtype=bool\n",
    "\n",
    "def get_union_of_shingles(shingles):\n",
    "    \"\"\"\n",
    "    Get the union of all shingles from a list of shingles.\n",
    "    Output is a sorted list of unique shingles.\n",
    "    \"\"\"\n",
    "    union = set()\n",
    "    for s in shingles:\n",
    "        union |= s\n",
    "    return sorted(union)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a list of hashed shingles `[shingles of documents 1, shingles of doucment 2, ..]` we generate the *characteristic matrix*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D0</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40852693</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209715022</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301143686</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460860852</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594259817</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3988809903</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4047504577</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128545898</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133237477</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4141725251</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            D0  D1  D2\n",
       "40852693     0   1   1\n",
       "209715022    0   1   1\n",
       "301143686    0   1   0\n",
       "460860852    0   1   0\n",
       "594259817    1   1   1\n",
       "...         ..  ..  ..\n",
       "3988809903   0   0   1\n",
       "4047504577   0   1   0\n",
       "4128545898   1   1   1\n",
       "4133237477   0   1   1\n",
       "4141725251   1   0   1\n",
       "\n",
       "[62 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hashed_shingles = [h3, h4, h5]\n",
    "df = get_characteristic_matrix(hashed_shingles)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating hash functions\n",
    "From [Stanford's slides, p. 39](http://www.mmds.org/mmds/v2.1/ch03-lsh.pdf):\n",
    "> How to pick a random hash function $h(x)$?\n",
    "> * $ h(x) = ( (ax + b) \\mod p ) \\mod N $, where $a$ and $b$ are random integers and $p$ is a prime number larger than $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MinHash gives the signature of a set. The signature is then used as a proxy for the characterstic matrix, and allows a computational-friendly estimate for the Jaccardian distance. For big datasets, the law of large numbers kicks in.\n",
    "\n",
    "For *k* (**k=100 recommended!**) independent hash functions, and according to the lecture, a hash function can look like this:\n",
    "\n",
    "$$\n",
    "h(x) \\equiv (ax + b) \\mod c\n",
    "$$\n",
    "\n",
    "> Pseudokod finnes i boken (och föreläsningen, 01:00:00 in!\n",
    "\n",
    "You may also use permutations to achieve the same result, but the föreläsare recommends hash functions. Not sure which apporach is easier to understand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# TODO fix magic number and approach all together\n",
    "\n",
    "def get_hash_function(N):\n",
    "    \"\"\"\n",
    "    Generate a hash function for a given N\n",
    "    \"\"\"\n",
    "    a = random.randint(0, N)\n",
    "    b = random.randint(0, N)\n",
    "    p = get_prime(N)\n",
    "    return lambda x: ((a * x + b) % p) % N\n",
    "\n",
    "# TODO naive implementation, not efficient, but then again, it's a one off\n",
    "def get_prime(N):\n",
    "    \"\"\"\n",
    "    Get a prime number larger than N\n",
    "    \"\"\"\n",
    "    n = random.randint(N*2, N*4)\n",
    "    while not is_prime(n):\n",
    "        n = random.randint(N*2, N*4)\n",
    "    return n\n",
    "\n",
    "def is_prime(n):\n",
    "    \"\"\"\n",
    "    Check if n is a prime number\n",
    "    \"\"\"\n",
    "    if n < 2:\n",
    "        return False\n",
    "    for i in range(2, n):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SANDBOX\n",
    "hash_functions = [get_hash_function(x) for x in range(20, 25)]\n",
    "len(hash_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashing the columns (documents) of the characteristic matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I generate a `len(hash_functions)` x `len(documents)` matrix, where each row is a hash function, and each column is a document. The value in each cell $hash_i(index_{row})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40852693</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209715022</th>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301143686</th>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460860852</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594259817</th>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3988809903</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4047504577</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128545898</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133237477</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4141725251</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0   1   2   3   4\n",
       "40852693    10   2  10   6  19\n",
       "209715022   11  19  17  12  16\n",
       "301143686   12  15   2  18  13\n",
       "460860852   13   0   9   1   3\n",
       "594259817   14  17  16   7   0\n",
       "...         ..  ..  ..  ..  ..\n",
       "3988809903   0  17  14  13   7\n",
       "4047504577   1  13  21  19   4\n",
       "4128545898   2   9   6   2   1\n",
       "4133237477   3  15  13   8  15\n",
       "4141725251   4  11  20  14  12\n",
       "\n",
       "[62 rows x 5 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from here on there is only sandboxing and testing\n",
    "data = []\n",
    "for index in range(len(df.index)):\n",
    "    data.append([f(index) for f in hash_functions])\n",
    "\n",
    "print(len(data), len(data[0]))\n",
    "\n",
    "df_hashed = pd.DataFrame(data=data, index=df.index, columns=range(len(hash_functions)))\n",
    "#df_hashed\n",
    "df_hashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hashed_minhash(df, hash_functions):\n",
    "    \"\"\"\n",
    "    df: a dataframe with rows as shingles and columns as documents.\n",
    "    hash_functions: a list of hash functions.\n",
    "    Compute the hashed minhash of a dataframe.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for index in range(len(df.index)):\n",
    "        data.append([f(index) for f in hash_functions])\n",
    "    return pd.DataFrame(data=data, index=df.index, columns=range(len(hash_functions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = compute_hashed_minhash(df, hash_functions).to_numpy()\n",
    "A = df.to_numpy()\n",
    "signature = np.full((len(hash_functions), len(df.columns)), np.inf)\n",
    "\n",
    "\n",
    "for i in range(len(df.columns)):\n",
    "    for j in range(len(hash_functions)):\n",
    "        for k in range(len(df.index)):\n",
    "            if A[k][i] == 1:\n",
    "                signature[j][i] = min(signature[j][i], B[k][j])\n",
    "\n",
    "signature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0, 14,  0, 16, 17, 18, 19,  0,  0,  2,  3,  4,  0,\n",
       "         0,  0,  8,  0, 10, 11,  0, 13,  0,  0, 16, 17, 18, 19,  0,  0,\n",
       "         2,  3,  0,  0,  0,  7,  0,  9, 10,  0, 12, 13, 14,  0, 16,  0,\n",
       "        18, 19,  0,  0,  0,  3,  4,  0,  6,  0,  0,  2,  0,  4],\n",
       "       [ 0,  0,  0,  0, 17,  0,  9, 15, 11,  7, 13,  0,  5, 11,  7,  0,\n",
       "         0,  0,  1,  0,  3, 20,  0,  1,  0,  0, 20, 16,  1, 18, 14,  0,\n",
       "        16, 12,  0,  0,  0,  6,  0,  8,  4,  0,  6,  2,  8,  0,  0,  0,\n",
       "         2, 19,  4,  0,  0,  2, 19,  0,  0,  0,  0,  9,  0, 11],\n",
       "       [ 0,  0,  0,  0, 16,  0,  8, 15,  0,  7,  1,  0, 15,  0,  7,  0,\n",
       "         0,  0, 13,  0,  5, 12,  0, 13,  0,  0, 12, 19,  4, 11, 18,  0,\n",
       "        10,  4,  0,  0,  0, 10,  0,  2,  9,  0,  1,  8,  2,  0, 16,  0,\n",
       "         8, 15,  0,  0,  0, 21,  6,  0,  7,  0,  0,  6,  0, 20],\n",
       "       [ 0,  0,  0,  0,  7,  0, 19,  2,  8, 14, 20,  0, 11, 17,  0,  0,\n",
       "         0,  0,  1,  0, 13, 19,  0, 10,  0,  0,  5, 11, 17,  0,  6,  0,\n",
       "        18,  3,  0,  0,  0,  4,  0, 16, 22,  0, 11, 17,  2,  0, 14,  0,\n",
       "         3,  9, 15,  0,  0, 10, 16,  0,  7,  0,  0,  2,  0, 14],\n",
       "       [ 0,  0,  0,  0,  0,  0, 18,  8,  5,  2, 23,  0, 10,  7,  4,  0,\n",
       "         0,  0,  2,  0, 20, 17,  0,  4,  0,  0, 12,  9,  6,  3, 17,  0,\n",
       "        11,  1,  0,  0,  0,  6,  0,  0, 21,  0,  8,  5,  2,  0, 13,  0,\n",
       "         0, 21, 18,  0,  0,  2, 23,  0, 10,  0,  0,  1,  0, 12]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = 0\n",
    "A.T[document]\n",
    "B.T*A.T[document]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(62, 3) (62, 5)\n",
      "35\n",
      "45\n",
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10494/3077321300.py:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  C = np.array(C)\n",
      "/tmp/ipykernel_10494/3077321300.py:33: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmin(np.array([[1,2,3], [np.nan,np.nan,np.nan], [1,2,3]]), axis=1, keepdims=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [nan],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hashed = compute_hashed_minhash(df, hash_functions)\n",
    "df_hashed.head()\n",
    "\n",
    "\n",
    "hashed_data = df_hashed.to_numpy()\n",
    "\n",
    "data = df_hashed.to_numpy() # data = B\n",
    "# idx is where the rows have 1 in the column\n",
    "idx = data > 0\n",
    "\n",
    "signature = np.full((len(hash_functions), len(df.columns)), np.inf)\n",
    "\n",
    "A = df.to_numpy()\n",
    "\n",
    "B = data\n",
    "\n",
    "print(A.shape, B.shape)\n",
    "A.T\n",
    "\n",
    "#np.take(B.T, A > 0)\n",
    "\n",
    "\n",
    "C = []\n",
    "for document in range(A.shape[1]):\n",
    "    row = list(map(lambda x: np.nanmin(x, keepdims=True), B[A[:,document] > 0]))\n",
    "    C.append(row)\n",
    "    print(len(row))\n",
    "\n",
    "C = np.array(C)\n",
    "C.shape\n",
    "\n",
    "np.nanmin(np.array([[1,2,3], [np.nan,np.nan,np.nan], [1,2,3]]), axis=1, keepdims=True)\n",
    "\n",
    "#df_c = pd.DataFrame(C, dtype=int)\n",
    "\n",
    "#df_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D0</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     D0   D1   D2\n",
       "0   0.0  0.0  0.0\n",
       "1   0.0  0.0  0.0\n",
       "2   0.0  0.0  0.0\n",
       "3   0.0  0.0  0.0\n",
       "4   0.0  0.0  0.0\n",
       "..  ...  ...  ...\n",
       "95  0.0  0.0  0.0\n",
       "96  0.0  0.0  0.0\n",
       "97  0.0  0.0  0.0\n",
       "98  0.0  0.0  0.0\n",
       "99  0.0  0.0  0.0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_signature = pd.DataFrame(columns=['D'+str(i) for i in range(len(hashed_shingles))], index=range(len(hash_functions)), dtype=int)\n",
    "df_signature[:] = signature\n",
    "df_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSH\n",
    "\n",
    "With the signature matrix at hand, we are supposed to reduce the number of required comparisons by generating *candidate pairs*, which much likely are going to be similar. This is done by using yet another matrix, the matrix *M*. Approach according to lecture:\n",
    "\n",
    "* Divide matrix *M* into *b* bands and *r* rows\n",
    "* For each band, hash its portion of each column to a hash table with *k* buckets (make *k* as large as possible)\n",
    "* Candidate column pair are those that hash to the same bucker for ≥ 1 band.\n",
    "* tune *b* and *r* to catch most similar pairs, but few non-similar pairs. \n",
    "\n",
    "Recommender *b* and *r* values, but for signatare matrix of 100 hashes *b* = 20, *r* = 5.\n",
    "\n",
    "> Statistiken gås igenom efter ca 1h 10m på föreläsningen. Förstår ej.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_candidate_pairs():\n",
    "    return null"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
